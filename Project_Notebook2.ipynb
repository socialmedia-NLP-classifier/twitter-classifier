{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries in this cell\n",
    "import pandas as pd #pandas is a library for data wrangling/handling\n",
    "import numpy as np #same case for numpy\n",
    "\n",
    "# Libraries for helping us with strings\n",
    "import string\n",
    "# Regular Expression Library\n",
    "import re\n",
    "\n",
    "# Seaborn / matplotlib for visualization \n",
    "import seaborn as sns\n",
    "# This command tells python to use seaborn for its styling.\n",
    "sns.set()\n",
    "\n",
    "\n",
    "# Matplotlib is also a very useful, basic visualization/plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "# Very important, this will make your charts appear in your notebook instead of in a new window.\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Provides z-score helper function,\n",
    "# z-score uses standard deviation to remove outliers\n",
    "# (industry standard is if a data point is 3 std devs away from mean,\n",
    "# it's considered to be an outlier)\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "# Ignore this, this is just for displaying images.\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "# Importing sklearn library\n",
    "import sklearn\n",
    "\n",
    "# Import the trees from sklearn\n",
    "from sklearn import tree\n",
    "\n",
    "# Metrics help us score our model, using metrics to evaluate our model\n",
    "from sklearn import metrics\n",
    "\n",
    "# Import our Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Import our Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Import our text vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# This is our Logit model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Importing our linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Helper fuctions to evaluate our model from sklearn, including f1_score.\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "# Some more helpful ML function\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Helper function to split our data for testing and training purposes\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Helper function for hyper-parameter turning.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import MultinomaialNB classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Import our Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Library for visualizing our tree\n",
    "# If you get an error, \n",
    "# run 'conda install python-graphviz' in your terminal (without the quotes).\n",
    "import graphviz \n",
    "\n",
    "\n",
    "# NLTK is our Natural-Language-Took-Kit\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# You may need to download these from nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "stopwords = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns in dataframe: (37249, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...        -1\n",
       "3  what you have learned yours and only yours wha...         0\n",
       "4  for your own benefit you may want read living ...         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First dataframe\n",
    "df_reddit_data = pd.read_csv('data/Reddit_Data.csv')\n",
    "print(\"Number of rows and columns in dataframe: \" + str(df_reddit_data.shape), '\\n')\n",
    "df_reddit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_comment    100\n",
      "category           0\n",
      "dtype: int64 \n",
      "\n",
      "clean_comment    0.27\n",
      "category         0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking for nulls\n",
    "print(df_reddit_data.isnull().sum(), '\\n')\n",
    "print(((df_reddit_data.isnull().sum() / len(df_reddit_data)) *100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping nulls\n",
    "df_reddit_data = df_reddit_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dupes are 350\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "print(\"Number of dupes are \" + str(df_reddit_data.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375      True\n",
       "392      True\n",
       "617      True\n",
       "651      True\n",
       "1222     True\n",
       "         ... \n",
       "36915    True\n",
       "37044    True\n",
       "37125    True\n",
       "37158    True\n",
       "37234    True\n",
       "Length: 350, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking which line exactly were duplicated\n",
    "condition = df_reddit_data.duplicated() == True\n",
    "df_reddit_data.duplicated()[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Dropping dupes\n",
    "df_reddit_data = df_reddit_data.drop_duplicates()\n",
    "print(df_reddit_data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls: clean_comment    0\n",
      "category         0\n",
      "dtype: int64\n",
      "\n",
      "Number of dupes are 0\n",
      "\n",
      "Number of rows after cleaning data:  36799\n"
     ]
    }
   ],
   "source": [
    "# Sanity Checking\n",
    "print('Number of nulls: ' + str(df_reddit_data.isnull().sum()))\n",
    "print(\"\\nNumber of dupes are \" + str(df_reddit_data.duplicated().sum()))\n",
    "# print(str(df_reddit_data.duplicated()[condition]))\n",
    "print('\\nNumber of rows after cleaning data: ', df_reddit_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clean_comment', 'category'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the type of columns, to see if some are faulty\n",
    "# including duplicated columns or faulty ones that don't have an name for example\n",
    "df_reddit_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns in dataframe: (162980, 2) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Second dataframe\n",
    "df_twitter_data = pd.read_csv('data/Twitter_Data.csv')\n",
    "print(\"Number of rows and columns in dataframe: \" + str(df_twitter_data.shape), '\\n')\n",
    "df_twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_text    4\n",
      "category      7\n",
      "dtype: int64 \n",
      "\n",
      "clean_text    0.0025\n",
      "category      0.0043\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking for nulls\n",
    "print(df_twitter_data.isnull().sum(), '\\n')\n",
    "print(((df_twitter_data.isnull().sum() / len(df_twitter_data)) *100).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_data = df_twitter_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dupes are 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of dupes are \" + str(df_twitter_data.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['clean_text', 'category'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the type of columns, to see if some are faulty\n",
    "# including duplicated columns or faulty ones that don't have an name for example\n",
    "df_twitter_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming 'clean_text' to 'clean_comment' like the reddit dataframe has\n",
    "# to facilitate the merging of both dataframes\n",
    "df_twitter_data = df_twitter_data.rename(columns = { \"clean_text\" : \"clean_comment\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls: clean_comment    0\n",
      "category         0\n",
      "dtype: int64\n",
      "\n",
      "Number of dupes are 0\n",
      "\n",
      "Number of rows after cleaning data:  162969\n"
     ]
    }
   ],
   "source": [
    "# Sanity Checking\n",
    "print('Number of nulls: ' + str(df_twitter_data.isnull().sum()))\n",
    "print(\"\\nNumber of dupes are \" + str(df_twitter_data.duplicated().sum()))\n",
    "# print(str(df_twitter_data.duplicated()[condition]))\n",
    "print('\\nNumber of rows after cleaning data: ', df_twitter_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1616, 1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jigaboo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mound of venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asslover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s&amp;m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>queaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whitetrash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          jigaboo\n",
       "0  mound of venus\n",
       "1        asslover\n",
       "2             s&m\n",
       "3           queaf\n",
       "4      whitetrash"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Third dataframe\n",
    "df_bad_words = pd.read_csv('data/bad-words.csv')\n",
    "print(df_bad_words.shape, '\\n')\n",
    "df_bad_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jigaboo    0\n",
      "dtype: int64 \n",
      "\n",
      "jigaboo    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking for nulls\n",
    "print(df_bad_words.isnull().sum(), '\\n')\n",
    "print(((df_bad_words.isnull().sum() / len(df_bad_words)) *100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dupes are 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "print(\"Number of dupes are \" + str(df_bad_words.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the column to something more clear and understandable\n",
    "df_bad_words = df_bad_words.rename(columns = { \"jigaboo\" : \"Profanity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls: Profanity    0\n",
      "dtype: int64\n",
      "\n",
      "Number of dupes are 0\n",
      "\n",
      "Number of rows after cleaning data:  1616\n"
     ]
    }
   ],
   "source": [
    "# Sanity Checking\n",
    "print('Number of nulls: ' + str(df_bad_words.isnull().sum()))\n",
    "print(\"\\nNumber of dupes are \" + str(df_bad_words.duplicated().sum()))\n",
    "# print(str(df_reddit_data.duplicated()[condition]))\n",
    "print('\\nNumber of rows after cleaning data: ', df_bad_words.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>americunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as_hell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asshole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bastard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Profanity\n",
       "0  americunt\n",
       "1   as_hell \n",
       "2       ass \n",
       "3    asshole\n",
       "4    bastard"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fourth dataframe\n",
    "# change underscores to hypens !!important\n",
    "df_more_bad_words = pd.read_csv('data/more_bad_words.csv')\n",
    "print(df_more_bad_words.shape, '\\n')\n",
    "df_more_bad_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profanity    0\n",
      "dtype: int64 \n",
      "\n",
      "Profanity    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking for nulls\n",
    "print(df_more_bad_words.isnull().sum(), '\\n')\n",
    "print(((df_more_bad_words.isnull().sum() / len(df_more_bad_words)) *100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dupes are 1\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates\n",
    "print(\"Number of dupes are \" + str(df_more_bad_words.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking which line exactly were duplicated\n",
    "condition = df_more_bad_words.duplicated() == True\n",
    "df_more_bad_words.duplicated()[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Dropping dupes\n",
    "df_more_bad_words = df_more_bad_words.drop_duplicates()\n",
    "print(df_more_bad_words.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls: Profanity    0\n",
      "dtype: int64\n",
      "\n",
      "Number of dupes are 0\n",
      "\n",
      "Number of rows after cleaning data:  99\n"
     ]
    }
   ],
   "source": [
    "# Sanity Checking\n",
    "print('Number of nulls: ' + str(df_more_bad_words.isnull().sum()))\n",
    "print(\"\\nNumber of dupes are \" + str(df_more_bad_words.duplicated().sum()))\n",
    "# print(str(df_reddit_data.duplicated()[condition]))\n",
    "print('\\nNumber of rows after cleaning data: ', df_more_bad_words.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My attempt at merging the reddit and twitter datasets together\n",
    "list_of_dataframes = [df_reddit_data, df_twitter_data]\n",
    "df_posts = pd.concat(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199768, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...       1.0\n",
       "1  buddhism has very much lot compatible with chr...       1.0\n",
       "2  seriously don say thing first all they won get...      -1.0\n",
       "3  what you have learned yours and only yours wha...       0.0\n",
       "4  for your own benefit you may want read living ...       1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(df_posts.shape))\n",
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1.,  0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just some more sanity checking\n",
    "df_posts.category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199763</th>\n",
       "      <td>162975</td>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199764</th>\n",
       "      <td>162976</td>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199765</th>\n",
       "      <td>162977</td>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199766</th>\n",
       "      <td>162978</td>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199767</th>\n",
       "      <td>162979</td>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199768 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                      clean_comment  category\n",
       "0            0   family mormon have never tried explain them t...       1.0\n",
       "1            1  buddhism has very much lot compatible with chr...       1.0\n",
       "2            2  seriously don say thing first all they won get...      -1.0\n",
       "3            3  what you have learned yours and only yours wha...       0.0\n",
       "4            4  for your own benefit you may want read living ...       1.0\n",
       "...        ...                                                ...       ...\n",
       "199763  162975  why these 456 crores paid neerav modi not reco...      -1.0\n",
       "199764  162976  dear rss terrorist payal gawar what about modi...      -1.0\n",
       "199765  162977  did you cover her interaction forum where she ...       0.0\n",
       "199766  162978  there big project came into india modi dream p...       0.0\n",
       "199767  162979  have you ever listen about like gurukul where ...       1.0\n",
       "\n",
       "[199768 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The index values of each row were messed up after cleaning the data\n",
    "# and merging/concatinating the data, so I used the following to make sure that \n",
    "# the index values in the new dataframe correspond to the correct tuple\n",
    "df_posts.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts = df_posts.reset_index()\n",
    "df_posts = df_posts.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199763</th>\n",
       "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199764</th>\n",
       "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199765</th>\n",
       "      <td>did you cover her interaction forum where she ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199766</th>\n",
       "      <td>there big project came into india modi dream p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199767</th>\n",
       "      <td>have you ever listen about like gurukul where ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_comment  category\n",
       "0        family mormon have never tried explain them t...       1.0\n",
       "1       buddhism has very much lot compatible with chr...       1.0\n",
       "2       seriously don say thing first all they won get...      -1.0\n",
       "3       what you have learned yours and only yours wha...       0.0\n",
       "4       for your own benefit you may want read living ...       1.0\n",
       "...                                                   ...       ...\n",
       "199763  why these 456 crores paid neerav modi not reco...      -1.0\n",
       "199764  dear rss terrorist payal gawar what about modi...      -1.0\n",
       "199765  did you cover her interaction forum where she ...       0.0\n",
       "199766  there big project came into india modi dream p...       0.0\n",
       "199767  have you ever listen about like gurukul where ...       1.0\n",
       "\n",
       "[199768 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking once again\n",
    "df_posts\n",
    "\n",
    "\n",
    "\n",
    "# Up until this part, everything went well. After this, I tried to merge the profanity data sets together.\n",
    "# Kukai suggested using a function that will reduce the phrase/term to the root value, so I'll lokk into that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My attempt at merging the profanity datasets together\n",
    "list_of_dataframes = [df_bad_words, df_more_bad_words]\n",
    "df_profanity = pd.concat(list_of_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1715, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mound of venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asslover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s&amp;m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>queaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whitetrash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Profanity\n",
       "0  mound of venus\n",
       "1        asslover\n",
       "2             s&m\n",
       "3           queaf\n",
       "4      whitetrash"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(df_profanity.shape))\n",
    "df_profanity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mound of venus', 'asslover', 's&m', ..., 'worthless', 'douche',\n",
       "       'islamophobia'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just some more sanity checking\n",
    "df_profanity.Profanity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mound of venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>asslover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>s&amp;m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>queaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>whitetrash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>94</td>\n",
       "      <td>retarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>95</td>\n",
       "      <td>delusional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>96</td>\n",
       "      <td>worthless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>97</td>\n",
       "      <td>douche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>99</td>\n",
       "      <td>islamophobia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1715 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       Profanity\n",
       "0         0  mound of venus\n",
       "1         1        asslover\n",
       "2         2             s&m\n",
       "3         3           queaf\n",
       "4         4      whitetrash\n",
       "...     ...             ...\n",
       "1710     94        retarded\n",
       "1711     95      delusional\n",
       "1712     96       worthless\n",
       "1713     97          douche\n",
       "1714     99    islamophobia\n",
       "\n",
       "[1715 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The index values of each row were messed up after cleaning the data\n",
    "# and merging/concatinating the data, so I used the following to make sure that \n",
    "# the index values in the new dataframe correspond to the correct tuple\n",
    "df_profanity.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profanity = df_profanity.reset_index()\n",
    "df_profanity = df_profanity.drop(columns = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mound of venus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>asslover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s&amp;m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>queaf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whitetrash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>retarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>delusional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>worthless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>douche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>islamophobia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1715 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Profanity\n",
       "0     mound of venus\n",
       "1           asslover\n",
       "2                s&m\n",
       "3              queaf\n",
       "4         whitetrash\n",
       "...              ...\n",
       "1710        retarded\n",
       "1711      delusional\n",
       "1712       worthless\n",
       "1713          douche\n",
       "1714    islamophobia\n",
       "\n",
       "[1715 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking once again\n",
    "df_profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of profane words that shouldn't be allowed\n",
    "profanity_list = df_profanity.Profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       mound of venus\n",
       "1             asslover\n",
       "2                  s&m\n",
       "3                queaf\n",
       "4           whitetrash\n",
       "             ...      \n",
       "1710          retarded\n",
       "1711        delusional\n",
       "1712         worthless\n",
       "1713            douche\n",
       "1714      islamophobia\n",
       "Name: Profanity, Length: 1715, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profanity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Profanity'], dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_profanity.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filer words out using profanity from df_bad_words\n",
    "def remove_profanity(profane_str):\n",
    "    \n",
    "    words = word_tokenize(profane_str)\n",
    "    \n",
    "    valid_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        if word not in profanity_list:\n",
    "            \n",
    "            valid_words.append(word)\n",
    "            \n",
    "    profane_str = ' '.join(valid_words)\n",
    "    \n",
    "    return profane_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seems like good practice to me, creating a single function that will call all\n",
    "# our necessary functions from one place, will be subject to change\n",
    "def text_pipeline(input_str):\n",
    "    input_str = remove_profanity(input_str)\n",
    "    return input_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Profanity\n",
      "52     fingerfucker \n",
      "55           assfuck\n",
      "58      mothafucked \n",
      "67           fuckers\n",
      "95        cuntfucker\n",
      "...              ...\n",
      "1652          fucks \n",
      "1653       fucktard \n",
      "1656    goatfuckers.\n",
      "1672    motherfucker\n",
      "1673  motherfucking \n",
      "\n",
      "[117 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# df[df['A'].str.contains(\"hello\")]\n",
    "print(str(df_profanity[df_profanity['Profanity'].str.contains(\"fuck\")]))\n",
    "# condition = profanity_list == \"fuck\"\n",
    "# profanity_list[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn profanity_list into a set rather than a dataframe so that its faster (constant time vs O(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look into root functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            clean_comment  category  \\\n",
      "27         demogorgon because fuck you and your shit god       -1.0   \n",
      "51       tea partier expresses support for namo after ...      -1.0   \n",
      "99      scheduled castes day before marriage parties a...      -1.0   \n",
      "118      deserves you think deserve such mainstream me...      -1.0   \n",
      "204      what the fuck giroud know only vietnam but damn       -1.0   \n",
      "...                                                   ...       ...   \n",
      "195239  this means modi finally focusing elections onl...      -1.0   \n",
      "195554  agree opposition too weak stand against bjp pr...      -1.0   \n",
      "197211  are all varanasi dumbfucks millionaires modi a...       0.0   \n",
      "198505  under modi government women are being empowere...       1.0   \n",
      "199105  who the fuck saying this modi right even said ...      -1.0   \n",
      "\n",
      "                               clean_comment_profane_free  \n",
      "27          demogorgon because fuck you and your shit god  \n",
      "51      tea partier expresses support for namo after e...  \n",
      "99      scheduled castes day before marriage parties a...  \n",
      "118     deserves you think deserve such mainstream med...  \n",
      "204       what the fuck giroud know only vietnam but damn  \n",
      "...                                                   ...  \n",
      "195239  this means modi finally focusing elections onl...  \n",
      "195554  agree opposition too weak stand against bjp pr...  \n",
      "197211  are all varanasi dumbfucks millionaires modi a...  \n",
      "198505  under modi government women are being empowere...  \n",
      "199105  who the fuck saying this modi right even said ...  \n",
      "\n",
      "[1933 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(str(df_posts[df_posts['clean_comment_profane_free'].str.contains(\"fuck\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n"
     ]
    }
   ],
   "source": [
    "# testing cell\n",
    "# df_posts['clean_comment_profane_free'][12802]\n",
    "df_posts['clean_comment_profane_free'].apply(text_pipeline)\n",
    "print(str(df_posts['clean_comment_profane_free'][12802]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fuck'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profane_str = df_posts['clean_comment'][12802]\n",
    "profane_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n",
      "\n",
      "str words:  ['fuck']\n",
      "In for loop \n",
      "\n",
      "\n",
      "if loop out:  fuck\n",
      "\n",
      "if loop in:  fuck\n",
      "['fuck'] \n",
      "\n",
      "\n",
      " fuck\n"
     ]
    }
   ],
   "source": [
    "profane_str = df_posts['clean_comment'][12802]\n",
    "\n",
    "print(profane_str)\n",
    "\n",
    "words = word_tokenize(profane_str)\n",
    "\n",
    "print('\\nstr words: ', str(words))\n",
    "\n",
    "valid_words = []\n",
    "    \n",
    "print(\"In for loop \\n\")\n",
    "for word in words:\n",
    "    print('\\nif loop out: ', str(word))\n",
    "    if word not in profanity_list:\n",
    "        print('\\nif loop in: ', str(word))\n",
    "        valid_words.append(word)\n",
    "            \n",
    "profane_str = ' '.join(valid_words)\n",
    "print(str(valid_words), '\\n')\n",
    "print('\\n', profane_str)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts['clean_comment_profane_free'] = df_posts['clean_comment']\n",
    "df_posts['clean_comment_profane_free'] = df_posts['clean_comment'].apply(text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12802\n"
     ]
    }
   ],
   "source": [
    "# So based off of some testing, the data set with the profanity (the second one on the google doc)\n",
    "# seems to have some really outlandish terms (and some I've never even heard of), but does\n",
    "# not have some standards ones like 'fuck', so I'm going to merge the other data set on the \n",
    "# the google doc so we can have some more standard insults included in the profanity list\n",
    "# and not have to make more work for ourselves, as merging seems to be fairly simple\n",
    "\n",
    "# r, c= np.where(df_posts.clean_comment == \"fuck\")\n",
    "\n",
    "# print ((next(iter(df_posts.index[r]), 'no match'), next(iter(df_posts.columns[c]), 'no match')))\n",
    "r= np.where(df_posts.clean_comment == \"fuck\")\n",
    "\n",
    "print ((next(iter(df_posts.index[r]), 'no match')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TEXT: fuck\n",
      "\n",
      "CLEANED TEXT: fuck\n"
     ]
    }
   ],
   "source": [
    "# Cell is used for testing profanity, above cell finds the record with the profane terms\n",
    "#Just for testing purposes\n",
    "print(\"ORIGINAL TEXT:\", df_posts['clean_comment'][12802])\n",
    "print(\"\\nCLEANED TEXT:\", df_posts['clean_comment_profane_free'][12802])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_comment_profane_free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category  \\\n",
       "0   family mormon have never tried explain them t...       1.0   \n",
       "1  buddhism has very much lot compatible with chr...       1.0   \n",
       "2  seriously don say thing first all they won get...      -1.0   \n",
       "3  what you have learned yours and only yours wha...       0.0   \n",
       "4  for your own benefit you may want read living ...       1.0   \n",
       "\n",
       "  clean_comment_profane_free  \n",
       "0                       None  \n",
       "1                       None  \n",
       "2                       None  \n",
       "3                       None  \n",
       "4                       None  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...        -1\n",
       "3  what you have learned yours and only yours wha...         0\n",
       "4  for your own benefit you may want read living ...         1"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reddit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_comment  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
